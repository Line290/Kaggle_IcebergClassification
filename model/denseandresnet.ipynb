{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, ZeroPadding2D\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend as K\n",
    "\n",
    "from custom_layers import Scale\n",
    "\n",
    "def DenseNet(nb_dense_block=2, growth_rate=16, nb_filter=32, reduction=0.0, dropout_rate=0.2, weight_decay=1e-4, classes=1, weights_path=None):\n",
    "    '''Instantiate the DenseNet 121 architecture,\n",
    "        # Arguments\n",
    "            nb_dense_block: number of dense blocks to add to end\n",
    "            growth_rate: number of filters to add per dense block\n",
    "            nb_filter: initial number of filters\n",
    "            reduction: reduction factor of transition blocks.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            classes: optional number of classes to classify images\n",
    "            weights_path: path to pre-trained weights\n",
    "        # Returns\n",
    "            A Keras model instance.\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    # bn\n",
    "    bn_momentum = 0.99\n",
    "    #\n",
    "    activation = 'elu'\n",
    "    # compute compression factor\n",
    "    compression = 1.0 - reduction\n",
    "\n",
    "    # Handle Dimension Ordering for different backends\n",
    "    global concat_axis\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "      concat_axis = 3\n",
    "      img_input = Input(shape=(75, 75, 3), name='data')\n",
    "    else:\n",
    "      concat_axis = 1\n",
    "      img_input = Input(shape=(3, 75, 75), name='data')\n",
    "    \n",
    "    angle_input = Input( shape = [1], name = 'angle' )\n",
    "\n",
    "    # From architecture for ImageNet (Table 1 in the paper)\n",
    "    nb_filter = 32\n",
    "    nb_layers = [2,4] # For DenseNet-121\n",
    "\n",
    "    # Initial convolution\n",
    "    x = ZeroPadding2D((1, 1), name='conv1_zeropadding')(img_input)\n",
    "    x = Convolution2D(nb_filter, 3, 3, subsample=(2, 2), name='conv1', bias=False)(x)\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv1_scale')(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "    x = ZeroPadding2D((1, 1), name='pool1_zeropadding')(x)\n",
    "    x = MaxPooling2D((5, 5), strides=(1, 1), name='pool1')(x)\n",
    "\n",
    "    # Add dense blocks\n",
    "    for block_idx in range(nb_dense_block - 1):\n",
    "        stage = block_idx+2\n",
    "        x, nb_filter = dense_block(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "        # Add transition_block\n",
    "        x = transition_block(x, stage, nb_filter, compression=compression, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "        nb_filter = int(nb_filter * compression)\n",
    "\n",
    "    final_stage = stage + 1\n",
    "    x, nb_filter = dense_block(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name='conv'+str(final_stage)+'_blk_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name='conv'+str(final_stage)+'_blk_scale')(x)\n",
    "    x = Activation('relu', name='relu'+str(final_stage)+'_blk')(x)\n",
    "    x = GlobalAveragePooling2D(name='pool'+str(final_stage))(x)\n",
    "    \n",
    "    #resnet\n",
    "    img_1 = Conv2D( 32, kernel_size = (3, 3), activation = activation, padding = 'same' ) ((BatchNormalization(momentum=bn_momentum) ) ( img_input) )\n",
    "    img_1 = MaxPooling2D( (2,2)) (img_1 )\n",
    "    img_1 = Dropout( 0.2 )( img_1 )\n",
    "\n",
    "    img_1 = Conv2D( 64, kernel_size = (3, 3), activation = activation, padding = 'same' ) ( (BatchNormalization(momentum=bn_momentum)) (img_1) )\n",
    "    img_1 = MaxPooling2D( (2,2) ) ( img_1 )\n",
    "    img_1 = Dropout( 0.2 )( img_1 )\n",
    "\n",
    "     # Residual block\n",
    "    img_2 = Conv2D( 128, kernel_size = (3, 3), activation = activation, padding = 'same' ) ( (BatchNormalization(momentum=bn_momentum)) (img_1) )\n",
    "    img_2 = Dropout(0.2) ( img_2 )\n",
    "    img_2 = Conv2D( 64, kernel_size = (3, 3), activation = activation, padding = 'same' ) ( (BatchNormalization(momentum=bn_momentum)) (img_2) )\n",
    "    img_2 = Dropout(0.2) ( img_2 )\n",
    "\n",
    "    img_res = add( [img_1, img_2] )\n",
    "\n",
    "    # Filter resudial output\n",
    "    img_res = Conv2D( 128, kernel_size = (3, 3), activation = activation ) ( (BatchNormalization(momentum=bn_momentum)) (img_res) )\n",
    "    img_res = MaxPooling2D( (2,2) ) ( img_res )\n",
    "    img_res = Dropout( 0.2 )( img_res )\n",
    "    img_res = GlobalMaxPooling2D() ( img_res )\n",
    "    \n",
    "    \n",
    "    x = ( Concatenate()( [x, img_res, BatchNormalization(momentum=bn_momentum)(angle_input)]) )\n",
    "    \n",
    "    dense_layer = Dropout( 0.5 ) ( BatchNormalization(momentum=bn_momentum) (Dense(512, activation = 'elu') (x)) )\n",
    "    dense_layer = Dropout( 0.5 ) ( BatchNormalization(momentum=bn_momentum) (Dense(256, activation = 'elu') (dense_layer)) )\n",
    "    x = Dense(classes, activation = 'sigmoid', name='fc6')(dense_layer)\n",
    "#     x = Activation('sigmoid', name='prob')(x)\n",
    "\n",
    "    model = Model([img_input, angle_input], x, name='densenet')\n",
    "    \n",
    "    opt = Adam( lr = 1e-3, beta_1 = .9, beta_2 = .999, decay = 1e-3 )\n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'] )\n",
    "\n",
    "    if weights_path is not None:\n",
    "      model.load_weights(weights_path)\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def conv_block(x, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):\n",
    "    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout\n",
    "        # Arguments\n",
    "            x: input tensor \n",
    "            stage: index for dense block\n",
    "            branch: layer index within each dense block\n",
    "            nb_filter: number of filters\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_' + str(branch)\n",
    "    relu_name_base = 'relu' + str(stage) + '_' + str(branch)\n",
    "\n",
    "    # 1x1 Convolution (Bottleneck layer)\n",
    "    inter_channel = nb_filter * 4  \n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x1_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_x1_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base+'_x1')(x)\n",
    "    x = Convolution2D(inter_channel, 1, 1, name=conv_name_base+'_x1', bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # 3x3 Convolution\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_x2_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_x2_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base+'_x2')(x)\n",
    "    x = ZeroPadding2D((1, 1), name=conv_name_base+'_x2_zeropadding')(x)\n",
    "    x = Convolution2D(nb_filter, 3, 3, name=conv_name_base+'_x2', bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transition_block(x, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
    "    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout \n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_filter: number of filters\n",
    "            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    conv_name_base = 'conv' + str(stage) + '_blk'\n",
    "    relu_name_base = 'relu' + str(stage) + '_blk'\n",
    "    pool_name_base = 'pool' + str(stage) \n",
    "\n",
    "    x = BatchNormalization(epsilon=eps, axis=concat_axis, name=conv_name_base+'_bn')(x)\n",
    "    x = Scale(axis=concat_axis, name=conv_name_base+'_scale')(x)\n",
    "    x = Activation('relu', name=relu_name_base)(x)\n",
    "    x = Convolution2D(int(nb_filter * compression), 1, 1, name=conv_name_base, bias=False)(x)\n",
    "\n",
    "    if dropout_rate:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = AveragePooling2D((2, 2), strides=(2, 2), name=pool_name_base)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dense_block(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True):\n",
    "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
    "        # Arguments\n",
    "            x: input tensor\n",
    "            stage: index for dense block\n",
    "            nb_layers: the number of layers of conv_block to append to the model.\n",
    "            nb_filter: number of filters\n",
    "            growth_rate: growth rate\n",
    "            dropout_rate: dropout rate\n",
    "            weight_decay: weight decay factor\n",
    "            grow_nb_filters: flag to decide to allow number of filters to grow\n",
    "    '''\n",
    "\n",
    "    eps = 1.1e-5\n",
    "    concat_feat = x\n",
    "\n",
    "    for i in range(nb_layers):\n",
    "        branch = i+1\n",
    "        x = conv_block(concat_feat, stage, branch, growth_rate, dropout_rate, weight_decay)\n",
    "        concat_feat = merge([concat_feat, x], mode='concat', concat_axis=concat_axis, name='concat_'+str(stage)+'_'+str(branch))\n",
    "\n",
    "        if grow_nb_filters:\n",
    "            nb_filter += growth_rate\n",
    "\n",
    "    return concat_feat, nb_filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D, Dense, Dropout, BatchNormalization, Input, Flatten, Activation\n",
    "from keras.layers.merge import Concatenate, add\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), strides=(2, 2), use_bias=False, name=\"conv1\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:136: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), use_bias=False, name=\"conv2_1_x1\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, name=\"conv2_1_x2\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:202: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/usr/local/lib/python2.7/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:136: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), use_bias=False, name=\"conv2_2_x1\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, name=\"conv2_2_x2\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:173: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), use_bias=False, name=\"conv2_blk\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:136: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), use_bias=False, name=\"conv3_1_x1\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, name=\"conv3_1_x2\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:136: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), use_bias=False, name=\"conv3_2_x1\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, name=\"conv3_2_x2\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:136: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), use_bias=False, name=\"conv3_3_x1\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, name=\"conv3_3_x2\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:136: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), use_bias=False, name=\"conv3_4_x1\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:146: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), use_bias=False, name=\"conv3_4_x2\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 75, 75, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_zeropadding (ZeroPadding2 (None, 77, 77, 3)    0           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 38, 38, 32)   864         conv1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 38, 38, 32)   128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_scale (Scale)             (None, 38, 38, 32)   64          conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 38, 38, 32)   0           conv1_scale[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool1_zeropadding (ZeroPadding2 (None, 40, 40, 32)   0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 36, 36, 32)   0           pool1_zeropadding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_x1_bn (BatchNormalizati (None, 36, 36, 32)   128         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_x1_scale (Scale)        (None, 36, 36, 32)   64          conv2_1_x1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu2_1_x1 (Activation)         (None, 36, 36, 32)   0           conv2_1_x1_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_x1 (Conv2D)             (None, 36, 36, 64)   2048        relu2_1_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 36, 36, 64)   0           conv2_1_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_x2_bn (BatchNormalizati (None, 36, 36, 64)   256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_x2_scale (Scale)        (None, 36, 36, 64)   128         conv2_1_x2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu2_1_x2 (Activation)         (None, 36, 36, 64)   0           conv2_1_x2_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_x2_zeropadding (ZeroPad (None, 38, 38, 64)   0           relu2_1_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1_x2 (Conv2D)             (None, 36, 36, 16)   9216        conv2_1_x2_zeropadding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 36, 36, 16)   0           conv2_1_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat_2_1 (Merge)              (None, 36, 36, 48)   0           pool1[0][0]                      \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_x1_bn (BatchNormalizati (None, 36, 36, 48)   192         concat_2_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_x1_scale (Scale)        (None, 36, 36, 48)   96          conv2_2_x1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu2_2_x1 (Activation)         (None, 36, 36, 48)   0           conv2_2_x1_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_x1 (Conv2D)             (None, 36, 36, 64)   3072        relu2_2_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 36, 36, 64)   0           conv2_2_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_x2_bn (BatchNormalizati (None, 36, 36, 64)   256         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_x2_scale (Scale)        (None, 36, 36, 64)   128         conv2_2_x2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu2_2_x2 (Activation)         (None, 36, 36, 64)   0           conv2_2_x2_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_x2_zeropadding (ZeroPad (None, 38, 38, 64)   0           relu2_2_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2_x2 (Conv2D)             (None, 36, 36, 16)   9216        conv2_2_x2_zeropadding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 36, 36, 16)   0           conv2_2_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat_2_2 (Merge)              (None, 36, 36, 64)   0           concat_2_1[0][0]                 \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_blk_bn (BatchNormalizatio (None, 36, 36, 64)   256         concat_2_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_blk_scale (Scale)         (None, 36, 36, 64)   128         conv2_blk_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "relu2_blk (Activation)          (None, 36, 36, 64)   0           conv2_blk_scale[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_blk (Conv2D)              (None, 36, 36, 64)   4096        relu2_blk[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 36, 36, 64)   0           conv2_blk[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (AveragePooling2D)        (None, 18, 18, 64)   0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_x1_bn (BatchNormalizati (None, 18, 18, 64)   256         pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_x1_scale (Scale)        (None, 18, 18, 64)   128         conv3_1_x1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu3_1_x1 (Activation)         (None, 18, 18, 64)   0           conv3_1_x1_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_x1 (Conv2D)             (None, 18, 18, 64)   4096        relu3_1_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 18, 18, 64)   0           conv3_1_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_x2_bn (BatchNormalizati (None, 18, 18, 64)   256         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_x2_scale (Scale)        (None, 18, 18, 64)   128         conv3_1_x2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu3_1_x2 (Activation)         (None, 18, 18, 64)   0           conv3_1_x2_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_x2_zeropadding (ZeroPad (None, 20, 20, 64)   0           relu3_1_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_1_x2 (Conv2D)             (None, 18, 18, 16)   9216        conv3_1_x2_zeropadding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 18, 18, 16)   0           conv3_1_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat_3_1 (Merge)              (None, 18, 18, 80)   0           pool2[0][0]                      \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_x1_bn (BatchNormalizati (None, 18, 18, 80)   320         concat_3_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_x1_scale (Scale)        (None, 18, 18, 80)   160         conv3_2_x1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu3_2_x1 (Activation)         (None, 18, 18, 80)   0           conv3_2_x1_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_x1 (Conv2D)             (None, 18, 18, 64)   5120        relu3_2_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 18, 18, 64)   0           conv3_2_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_x2_bn (BatchNormalizati (None, 18, 18, 64)   256         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_x2_scale (Scale)        (None, 18, 18, 64)   128         conv3_2_x2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu3_2_x2 (Activation)         (None, 18, 18, 64)   0           conv3_2_x2_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_x2_zeropadding (ZeroPad (None, 20, 20, 64)   0           relu3_2_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_2_x2 (Conv2D)             (None, 18, 18, 16)   9216        conv3_2_x2_zeropadding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 18, 18, 16)   0           conv3_2_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat_3_2 (Merge)              (None, 18, 18, 96)   0           concat_3_1[0][0]                 \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_x1_bn (BatchNormalizati (None, 18, 18, 96)   384         concat_3_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_x1_scale (Scale)        (None, 18, 18, 96)   192         conv3_3_x1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu3_3_x1 (Activation)         (None, 18, 18, 96)   0           conv3_3_x1_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_x1 (Conv2D)             (None, 18, 18, 64)   6144        relu3_3_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 18, 18, 64)   0           conv3_3_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_x2_bn (BatchNormalizati (None, 18, 18, 64)   256         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_x2_scale (Scale)        (None, 18, 18, 64)   128         conv3_3_x2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "relu3_3_x2 (Activation)         (None, 18, 18, 64)   0           conv3_3_x2_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_x2_zeropadding (ZeroPad (None, 20, 20, 64)   0           relu3_3_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 75, 75, 3)    12          data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_3_x2 (Conv2D)             (None, 18, 18, 16)   9216        conv3_3_x2_zeropadding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 75, 75, 32)   896         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 18, 18, 16)   0           conv3_3_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 37, 37, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concat_3_3 (Merge)              (None, 18, 18, 112)  0           concat_3_2[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 37, 37, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_x1_bn (BatchNormalizati (None, 18, 18, 112)  448         concat_3_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 37, 37, 32)   128         dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_x1_scale (Scale)        (None, 18, 18, 112)  224         conv3_4_x1_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 37, 37, 64)   18496       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "relu3_4_x1 (Activation)         (None, 18, 18, 112)  0           conv3_4_x1_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 18, 18, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_x1 (Conv2D)             (None, 18, 18, 64)   7168        relu3_4_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 18, 18, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 18, 18, 64)   0           conv3_4_x1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 18, 18, 64)   256         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_x2_bn (BatchNormalizati (None, 18, 18, 64)   256         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 18, 18, 128)  73856       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_x2_scale (Scale)        (None, 18, 18, 64)   128         conv3_4_x2_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 18, 18, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu3_4_x2 (Activation)         (None, 18, 18, 64)   0           conv3_4_x2_scale[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 18, 18, 128)  512         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_x2_zeropadding (ZeroPad (None, 20, 20, 64)   0           relu3_4_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 18, 18, 64)   73792       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_4_x2 (Conv2D)             (None, 18, 18, 16)   9216        conv3_4_x2_zeropadding[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 18, 18, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 18, 18, 16)   0           conv3_4_x2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 18, 18, 64)   0           dropout_15[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat_3_4 (Merge)              (None, 18, 18, 128)  0           concat_3_3[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 18, 18, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_blk_bn (BatchNormalizatio (None, 18, 18, 128)  512         concat_3_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 128)  73856       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_blk_scale (Scale)         (None, 18, 18, 128)  256         conv3_blk_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu3_blk (Activation)          (None, 18, 18, 128)  0           conv3_blk_scale[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 8, 8, 128)    0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "angle (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (GlobalAveragePooling2D)  (None, 128)          0           relu3_blk[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d_1 (GlobalM (None, 128)          0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1)            4           angle[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 257)          0           pool3[0][0]                      \n",
      "                                                                 global_max_pooling2d_1[0][0]     \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          132096      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 512)          2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 512)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 256)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fc6 (Dense)                     (None, 1)            257         dropout_20[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 602,961\n",
      "Trainable params: 598,761\n",
      "Non-trainable params: 4,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3528 samples, validate on 295 samples\n",
      "Epoch 1/100\n",
      " - 177s - loss: 0.5643 - acc: 0.7738 - val_loss: 5.1838 - val_acc: 0.4678\n",
      "Epoch 2/100\n",
      " - 15s - loss: 0.4234 - acc: 0.8223 - val_loss: 1.7047 - val_acc: 0.4847\n",
      "Epoch 3/100\n",
      " - 15s - loss: 0.3800 - acc: 0.8416 - val_loss: 1.2078 - val_acc: 0.5220\n",
      "Epoch 4/100\n",
      " - 15s - loss: 0.3294 - acc: 0.8583 - val_loss: 0.4947 - val_acc: 0.7898\n",
      "Epoch 5/100\n",
      " - 15s - loss: 0.3029 - acc: 0.8722 - val_loss: 0.2772 - val_acc: 0.8746\n",
      "Epoch 6/100\n",
      " - 15s - loss: 0.2823 - acc: 0.8750 - val_loss: 0.2920 - val_acc: 0.8949\n",
      "Epoch 7/100\n",
      " - 15s - loss: 0.2605 - acc: 0.8909 - val_loss: 0.2971 - val_acc: 0.8814\n",
      "Epoch 8/100\n",
      " - 14s - loss: 0.2458 - acc: 0.8980 - val_loss: 0.3607 - val_acc: 0.8814\n",
      "Epoch 9/100\n",
      " - 15s - loss: 0.2282 - acc: 0.9073 - val_loss: 0.2720 - val_acc: 0.8983\n",
      "Epoch 10/100\n",
      " - 15s - loss: 0.2294 - acc: 0.9099 - val_loss: 0.2560 - val_acc: 0.8915\n",
      "Epoch 11/100\n",
      " - 15s - loss: 0.2226 - acc: 0.9090 - val_loss: 0.6753 - val_acc: 0.7458\n",
      "Epoch 12/100\n",
      " - 15s - loss: 0.2132 - acc: 0.9152 - val_loss: 0.3808 - val_acc: 0.8542\n",
      "Epoch 13/100\n",
      " - 15s - loss: 0.1850 - acc: 0.9269 - val_loss: 0.2747 - val_acc: 0.9051\n",
      "Epoch 14/100\n",
      " - 15s - loss: 0.1886 - acc: 0.9255 - val_loss: 0.3459 - val_acc: 0.8814\n",
      "Epoch 15/100\n",
      " - 15s - loss: 0.1589 - acc: 0.9391 - val_loss: 0.4996 - val_acc: 0.8576\n",
      "Epoch 16/100\n",
      " - 15s - loss: 0.1958 - acc: 0.9257 - val_loss: 0.2882 - val_acc: 0.9017\n",
      "Epoch 17/100\n",
      " - 15s - loss: 0.1573 - acc: 0.9399 - val_loss: 0.3545 - val_acc: 0.8847\n",
      "Epoch 18/100\n",
      " - 15s - loss: 0.1340 - acc: 0.9521 - val_loss: 0.4230 - val_acc: 0.8814\n",
      "Epoch 19/100\n",
      " - 15s - loss: 0.1445 - acc: 0.9436 - val_loss: 0.3440 - val_acc: 0.8678\n",
      "Epoch 20/100\n",
      " - 15s - loss: 0.1340 - acc: 0.9478 - val_loss: 0.5186 - val_acc: 0.8814\n",
      "Epoch 21/100\n",
      " - 14s - loss: 0.1333 - acc: 0.9484 - val_loss: 0.3512 - val_acc: 0.8847\n",
      "Epoch 22/100\n",
      " - 14s - loss: 0.1210 - acc: 0.9552 - val_loss: 0.4503 - val_acc: 0.8983\n",
      "Epoch 23/100\n",
      " - 15s - loss: 0.1052 - acc: 0.9575 - val_loss: 0.4778 - val_acc: 0.8780\n",
      "Epoch 24/100\n",
      " - 15s - loss: 0.1253 - acc: 0.9507 - val_loss: 0.5260 - val_acc: 0.8847\n",
      "Epoch 25/100\n",
      " - 15s - loss: 0.1093 - acc: 0.9637 - val_loss: 0.4269 - val_acc: 0.8983\n",
      "Epoch 26/100\n",
      " - 15s - loss: 0.1182 - acc: 0.9544 - val_loss: 0.8512 - val_acc: 0.8102\n",
      "Epoch 27/100\n",
      " - 15s - loss: 0.1014 - acc: 0.9615 - val_loss: 0.6118 - val_acc: 0.8847\n",
      "Epoch 28/100\n",
      " - 15s - loss: 0.0750 - acc: 0.9736 - val_loss: 0.7151 - val_acc: 0.8271\n",
      "Epoch 29/100\n",
      " - 15s - loss: 0.0908 - acc: 0.9651 - val_loss: 0.4263 - val_acc: 0.8949\n",
      "Epoch 30/100\n",
      " - 15s - loss: 0.1079 - acc: 0.9606 - val_loss: 0.4552 - val_acc: 0.8881\n",
      "Model fitting done. Total time: 10m 14s\n",
      "295/295 [==============================] - 0s 653us/step\n",
      "Validation score: 0.25599\n",
      "Validation accuracy: 89.15%\n",
      "('====================', '\\n')\n"
     ]
    }
   ],
   "source": [
    "def get_callbacks( weight_save_path, no_improv_epochs = 10, min_delta = 1e-4 ):\n",
    "    es = EarlyStopping( 'val_loss', patience = no_improv_epochs, mode = 'min', min_delta = min_delta )\n",
    "    ms = ModelCheckpoint( weight_save_path, 'val_loss', save_best_only = True )\n",
    "\n",
    "    return [ es, ms ]\n",
    "\n",
    "def get_scaled_imgs(df):\n",
    "    imgs = []\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "        a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "        b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "        c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "        imgs.append(np.dstack((a, b, c)))\n",
    "\n",
    "    return np.array(imgs)\n",
    "\n",
    "def generate_data( data ):\n",
    "    X_band_1=np.array( [np.array(band).astype(np.float32).reshape(75, 75) \n",
    "                        for band in data['band_1']] )\n",
    "    X_band_2=np.array( [np.array(band).astype(np.float32).reshape(75, 75) \n",
    "                        for band in data['band_2']] )\n",
    "    X = np.concatenate( [X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis], \\\n",
    "                        ((X_band_1 + X_band_2)/2)[:, :, :, np.newaxis]], axis=-1 )\n",
    "    return X\n",
    "\n",
    "def augment_data( generator, X1, X2, y, batch_size = 32 ):\n",
    "    generator_seed = np.random.randint( 9999 )\n",
    "    gen_X1 = generator.flow( X1, y, batch_size = batch_size, seed = generator_seed )\n",
    "    gen_X2 = generator.flow( X1, X2, batch_size = batch_size, seed = generator_seed )\n",
    "\n",
    "    while True:\n",
    "        X1i = gen_X1.next()\n",
    "        X2i = gen_X2.next()\n",
    "\n",
    "        yield [ X1i[0], X2i[1] ], X1i[1]\n",
    "    \n",
    "def plot_band_samples( data, band = 1, title = None ):\n",
    "    fig = plt.figure( 1, figsize=(15, 15) )\n",
    "    for i in range(9):\n",
    "        ax = fig.add_subplot( 3, 3, i + 1 )\n",
    "        arr = np.reshape( np.array(data.iloc[i, band - 1]), (75, 75) )\n",
    "        ax.imshow( arr, cmap='inferno' )\n",
    "        fig.suptitle( title )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_bands( data, title = None ):\n",
    "    fig = plt.figure( 1, figsize = (15, 15) )\n",
    "    count = 1\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            ax = fig.add_subplot( 3, 3, count )\n",
    "            ax.imshow( data[i, :, :, j], cmap = 'inferno' )\n",
    "            count += 1\n",
    "            if i == 0:\n",
    "                if j == 0:\n",
    "                    ax.set_title( 'Band 1' , fontsize = 12)\n",
    "                elif j == 1:\n",
    "                    ax.set_title( 'Band 2', fontsize = 12 )\n",
    "                elif j == 2:\n",
    "                    ax.set_title( 'Average', fontsize = 12 )\n",
    "    fig.suptitle( title, fontsize = 14, fontweight = 'bold' )\n",
    "    plt.show()\n",
    "\n",
    "def make_plots( data, band_samples = True, all_bands = True ):\n",
    "    ships = data[ data.is_iceberg == 0 ].sample( n = 9, random_state = 42 )\n",
    "    icebergs = data[ data.is_iceberg == 1 ].sample( n = 9, random_state = 42 )\n",
    "\n",
    "    np_ships = generate_data( ships )\n",
    "    np_icebergs = generate_data( icebergs )\n",
    "    \n",
    "    if band_samples:\n",
    "        plot_band_samples( ships, band = 2, title = 'Ship image samples' )\n",
    "        plot_band_samples( icebergs, band = 2, title = 'Iceberg image samples' )\n",
    "\n",
    "    if all_bands:\n",
    "        plot_all_bands( np_ships, 'Image bands for ships' )\n",
    "        plot_all_bands( np_icebergs, 'Image bands for icebergs' )\n",
    "\n",
    " \n",
    " \n",
    " \n",
    "TEST = True # Should test data be passed to the model?\n",
    "DO_PLOT = False # Exploratory data plots\n",
    "USE_AUGMENTATION = False # Whether or not image augmentations should be made\n",
    "TRAIN_PATH = 'kaggle_lceberg_data/train.json'\n",
    "TEST_PATH = 'kaggle_lceberg_data/test.json'\n",
    "WEIGHT_SAVE_PATH = 'model_weights.hdf5'\n",
    "PREDICTION_SAVE_PATH = 'kaggle_lceberg_data/submission'\n",
    "\n",
    "if TEST:\n",
    "    SEED = np.random.randint( 9999 )\n",
    "else:\n",
    "    SEED = 42 # Constant seed for comparability between runs\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100 # Increase this\n",
    "\n",
    "train_data = pd.read_json( TRAIN_PATH )\n",
    "# train_data[ 'inc_angle' ] = train_data[ 'inc_angle' ].replace('na', 0)\n",
    "# train_data[ 'inc_angle' ] = train_data[ 'inc_angle' ].astype(float).fillna(0.0)\n",
    "\n",
    "# X = generate_data( train_data )\n",
    "X = get_scaled_imgs(train_data)\n",
    "X_a = train_data[ 'inc_angle' ]\n",
    "y = train_data[ 'is_iceberg' ]\n",
    "\n",
    "train_data.inc_angle = train_data.inc_angle.replace('na',0)\n",
    "idx_tr = np.where(train_data.inc_angle>0)\n",
    "\n",
    "\n",
    "y = y[idx_tr[0]]\n",
    "X_a = X_a[idx_tr[0]]\n",
    "X = X[idx_tr[0],...]\n",
    "\n",
    "def get_more_images(imgs):\n",
    "    \n",
    "    more_images = []\n",
    "    vert_flip_imgs = []\n",
    "    hori_flip_imgs = []\n",
    "      \n",
    "    for i in range(0,imgs.shape[0]):\n",
    "        a=imgs[i,:,:,0]\n",
    "        b=imgs[i,:,:,1]\n",
    "        c=imgs[i,:,:,2]\n",
    "        \n",
    "        av=cv2.flip(a,1)\n",
    "        ah=cv2.flip(a,0)\n",
    "        bv=cv2.flip(b,1)\n",
    "        bh=cv2.flip(b,0)\n",
    "        cv=cv2.flip(c,1)\n",
    "        ch=cv2.flip(c,0)\n",
    "        \n",
    "        vert_flip_imgs.append(np.dstack((av, bv, cv)))\n",
    "        hori_flip_imgs.append(np.dstack((ah, bh, ch)))\n",
    "      \n",
    "    v = np.array(vert_flip_imgs)\n",
    "    h = np.array(hori_flip_imgs)\n",
    "       \n",
    "    more_images = np.concatenate((imgs,v,h))\n",
    "    \n",
    "    return more_images\n",
    "\n",
    "X_train, X_val, X_angle_train, X_angle_val, y_train, y_val = train_test_split( X, X_a, y, train_size = .8, random_state = SEED )\n",
    "\n",
    "X_train = get_more_images(X_train)\n",
    "X_angle_train = np.concatenate((X_angle_train,X_angle_train,X_angle_train))\n",
    "y_train = np.concatenate((y_train,y_train,y_train))\n",
    "\n",
    "# X = get_more_images(X)\n",
    "# X_a = np.concatenate((X_a,X_a,X_a))\n",
    "# y = np.concatenate((y,y,y))\n",
    "\n",
    "if DO_PLOT:\n",
    "    make_plots( train_data, band_samples = True, all_bands = True )\n",
    "\n",
    "# X_train, X_val, X_angle_train, X_angle_val, y_train, y_val = train_test_split( X, X_a, y, train_size = .9, random_state = SEED )\n",
    "callback_list = get_callbacks( WEIGHT_SAVE_PATH, 20 )\n",
    "\n",
    "model = DenseNet()\n",
    "start_time = time.time()\n",
    "\n",
    "if USE_AUGMENTATION:\n",
    "    image_augmentation = ImageDataGenerator( rotation_range = 20,\n",
    "                                             horizontal_flip = True,\n",
    "                                             vertical_flip = True,\n",
    "                                             width_shift_range = .3,\n",
    "                                             height_shift_range =.3,\n",
    "                                             zoom_range = .1 )\n",
    "    input_generator = augment_data( image_augmentation, X_train, X_angle_train, y_train, batch_size = BATCH_SIZE )\n",
    "\n",
    "    model.fit_generator( input_generator, steps_per_epoch = 4096/BATCH_SIZE, epochs = EPOCHS,\n",
    "                         callbacks = callback_list, verbose = 2, \n",
    "                         validation_data = augment_data(image_augmentation, X_val, X_angle_val, y_val, batch_size = BATCH_SIZE),\n",
    "                         validation_steps = len(X_val)/BATCH_SIZE )\n",
    "\n",
    "else: \n",
    "    # Just fit model to the given training data\n",
    "    model.fit( [X_train, X_angle_train], y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, verbose = 2, \n",
    "               validation_data = ([X_val, X_angle_val], y_val), callbacks = callback_list )\n",
    "\n",
    "m, s = divmod( time.time() - start_time, 60 )\n",
    "print( 'Model fitting done. Total time: {}m {}s'.format(int(m), int(s)) )\n",
    "\n",
    "model.load_weights( WEIGHT_SAVE_PATH )\n",
    "val_score = model.evaluate( [X_val, X_angle_val], y_val, verbose = 1 )\n",
    "print( 'Validation score: {}'.format(round(val_score[0], 5)) )\n",
    "print( 'Validation accuracy: {}%'.format(round(val_score[1]*100, 2)) )\n",
    "print( '='*20, '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
