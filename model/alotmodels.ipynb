{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n===================FOLD=', 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:160: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 14s 588ms/step - loss: 0.7869 - acc: 0.5638 - val_loss: 0.6134 - val_acc: 0.6335\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.7212 - acc: 0.5443 - val_loss: 0.5694 - val_acc: 0.5311\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 0.6221 - acc: 0.5729 - val_loss: 0.5108 - val_acc: 0.7112\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.7015 - acc: 0.5483 - val_loss: 0.7120 - val_acc: 0.4689\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.7197 - acc: 0.5052 - val_loss: 0.6949 - val_acc: 0.4814: 0s - loss: 0.7255 -\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.7166 - acc: 0.4987 - val_loss: 0.6919 - val_acc: 0.5155\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.7151 - acc: 0.4974 - val_loss: 0.6903 - val_acc: 0.5466\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.7177 - acc: 0.4870 - val_loss: 0.6983 - val_acc: 0.4689\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.7024 - acc: 0.4922 - val_loss: 0.6850 - val_acc: 0.5311\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.6988 - acc: 0.5169 - val_loss: 0.6854 - val_acc: 0.6211\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.6827 - acc: 0.5613 - val_loss: 0.6629 - val_acc: 0.6056\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.6518 - acc: 0.5722 - val_loss: 0.5937 - val_acc: 0.6677\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.6290 - acc: 0.5677 - val_loss: 0.5188 - val_acc: 0.7733\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.5590 - acc: 0.5738 - val_loss: 0.5250 - val_acc: 0.7174\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.7280 - acc: 0.5247 - val_loss: 0.6921 - val_acc: 0.5311\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.7064 - acc: 0.5000 - val_loss: 0.6934 - val_acc: 0.4658\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.6981 - acc: 0.4805 - val_loss: 0.6929 - val_acc: 0.5280\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.6977 - acc: 0.4974 - val_loss: 0.6925 - val_acc: 0.5311\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.6919 - acc: 0.5339 - val_loss: 0.6920 - val_acc: 0.5311\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.6964 - acc: 0.4935 - val_loss: 0.6941 - val_acc: 0.4689\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.6938 - acc: 0.5274 - val_loss: 0.6931 - val_acc: 0.5186\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.6887 - acc: 0.5534 - val_loss: 0.6919 - val_acc: 0.5311\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.6950 - acc: 0.5091 - val_loss: 0.6929 - val_acc: 0.5280\n",
      "('Train loss:', 0.52528758177333246)\n",
      "('Train accuracy:', 0.69500780031201248)\n",
      "('Test loss:', 0.51078986566259255)\n",
      "('Test accuracy:', 0.71118012422360244)\n",
      "('\\n===================FOLD=', 1)\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 14s 583ms/step - loss: 1.3155 - acc: 0.5234 - val_loss: 0.7598 - val_acc: 0.5296\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 1.0819 - acc: 0.5592 - val_loss: 0.6644 - val_acc: 0.5701\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 1.0372 - acc: 0.5638 - val_loss: 0.9943 - val_acc: 0.6075\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 1.0673 - acc: 0.5559 - val_loss: 0.5200 - val_acc: 0.7040\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.8186 - acc: 0.6497 - val_loss: 0.3024 - val_acc: 0.8474\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.6259 - acc: 0.7209 - val_loss: 0.2788 - val_acc: 0.8474\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.5927 - acc: 0.7705 - val_loss: 0.3378 - val_acc: 0.8287\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.5410 - acc: 0.7734 - val_loss: 0.3245 - val_acc: 0.8349\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.5219 - acc: 0.7731 - val_loss: 0.2547 - val_acc: 0.8816\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.4640 - acc: 0.8047 - val_loss: 0.3485 - val_acc: 0.7913\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.4341 - acc: 0.8161 - val_loss: 0.2396 - val_acc: 0.8972\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.4510 - acc: 0.8249 - val_loss: 0.2396 - val_acc: 0.8692\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 0.4370 - acc: 0.8190 - val_loss: 0.2074 - val_acc: 0.9097\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3625 - acc: 0.8579 - val_loss: 0.2964 - val_acc: 0.8879\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3786 - acc: 0.8424 - val_loss: 0.2383 - val_acc: 0.8941\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3791 - acc: 0.8327 - val_loss: 0.2376 - val_acc: 0.9003\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.3982 - acc: 0.8216 - val_loss: 0.1965 - val_acc: 0.9283\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3414 - acc: 0.8366 - val_loss: 0.2204 - val_acc: 0.8972\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3407 - acc: 0.8657 - val_loss: 0.1979 - val_acc: 0.9190\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.2974 - acc: 0.8646 - val_loss: 0.1847 - val_acc: 0.9315\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.3151 - acc: 0.8761 - val_loss: 0.2251 - val_acc: 0.8816\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2854 - acc: 0.8737 - val_loss: 0.2113 - val_acc: 0.9097\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3881 - acc: 0.8565 - val_loss: 0.2125 - val_acc: 0.9128\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3149 - acc: 0.8565 - val_loss: 0.1896 - val_acc: 0.9315\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3438 - acc: 0.8646 - val_loss: 0.2401 - val_acc: 0.9034\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2691 - acc: 0.8774 - val_loss: 0.1909 - val_acc: 0.9159\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 0.2795 - acc: 0.8750 - val_loss: 0.1743 - val_acc: 0.9252\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3322 - acc: 0.8458 - val_loss: 0.1862 - val_acc: 0.9346\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2532 - acc: 0.9023 - val_loss: 0.1874 - val_acc: 0.9252\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.3037 - acc: 0.8536 - val_loss: 0.1673 - val_acc: 0.9252\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2583 - acc: 0.8787 - val_loss: 0.1970 - val_acc: 0.9346\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2932 - acc: 0.8737 - val_loss: 0.1683 - val_acc: 0.9377\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.2578 - acc: 0.8771 - val_loss: 0.1623 - val_acc: 0.9408\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.2464 - acc: 0.8919 - val_loss: 0.1567 - val_acc: 0.9408\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2744 - acc: 0.8901 - val_loss: 0.1955 - val_acc: 0.9159\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2696 - acc: 0.8800 - val_loss: 0.2169 - val_acc: 0.9097\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2636 - acc: 0.8763 - val_loss: 0.1956 - val_acc: 0.9097\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1993 - acc: 0.9165 - val_loss: 0.2078 - val_acc: 0.9128\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2469 - acc: 0.9023 - val_loss: 0.1636 - val_acc: 0.9346\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2006 - acc: 0.9139 - val_loss: 0.1653 - val_acc: 0.9377\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.3075 - acc: 0.8927 - val_loss: 0.2042 - val_acc: 0.9283\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3851 - acc: 0.8138 - val_loss: 0.2202 - val_acc: 0.9159\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2726 - acc: 0.8823 - val_loss: 0.2500 - val_acc: 0.9159\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2384 - acc: 0.9010 - val_loss: 0.1834 - val_acc: 0.9252\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.3215 - acc: 0.8640 - val_loss: 0.1805 - val_acc: 0.9408\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2489 - acc: 0.9023 - val_loss: 0.1639 - val_acc: 0.9377\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2813 - acc: 0.8800 - val_loss: 0.1932 - val_acc: 0.9315\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2502 - acc: 0.8888 - val_loss: 0.1681 - val_acc: 0.9439\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.2024 - acc: 0.9076 - val_loss: 0.1506 - val_acc: 0.9564\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2425 - acc: 0.8983 - val_loss: 0.2030 - val_acc: 0.9159\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2197 - acc: 0.9089 - val_loss: 0.1848 - val_acc: 0.9439\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2096 - acc: 0.9231 - val_loss: 0.1835 - val_acc: 0.9283\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2197 - acc: 0.9009 - val_loss: 0.1657 - val_acc: 0.9283\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2293 - acc: 0.9036 - val_loss: 0.1639 - val_acc: 0.9346\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.2208 - acc: 0.9022 - val_loss: 0.1471 - val_acc: 0.9439\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1695 - acc: 0.9258 - val_loss: 0.2086 - val_acc: 0.9252\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2764 - acc: 0.9084 - val_loss: 0.2062 - val_acc: 0.9128\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2045 - acc: 0.9115 - val_loss: 0.1914 - val_acc: 0.9252\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1795 - acc: 0.9322 - val_loss: 0.2292 - val_acc: 0.9097\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2101 - acc: 0.9218 - val_loss: 0.1608 - val_acc: 0.9377\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1851 - acc: 0.9245 - val_loss: 0.1719 - val_acc: 0.9190\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2369 - acc: 0.9084 - val_loss: 0.2045 - val_acc: 0.9003\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2026 - acc: 0.9128 - val_loss: 0.1550 - val_acc: 0.9408\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1881 - acc: 0.9240 - val_loss: 0.1596 - val_acc: 0.9408\n",
      "Epoch 65/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.2138 - acc: 0.9113 - val_loss: 0.1460 - val_acc: 0.9346\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.1718 - acc: 0.9271 - val_loss: 0.1406 - val_acc: 0.9346\n",
      "Epoch 67/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1950 - acc: 0.9257 - val_loss: 0.1763 - val_acc: 0.9315\n",
      "Epoch 68/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1951 - acc: 0.9154 - val_loss: 0.2029 - val_acc: 0.9159\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2020 - acc: 0.9087 - val_loss: 0.1658 - val_acc: 0.9408\n",
      "Epoch 70/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1716 - acc: 0.9258 - val_loss: 0.1602 - val_acc: 0.9252\n",
      "Epoch 71/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1921 - acc: 0.9244 - val_loss: 0.1841 - val_acc: 0.9190\n",
      "Epoch 72/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1751 - acc: 0.9283 - val_loss: 0.1518 - val_acc: 0.9470\n",
      "Epoch 73/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1688 - acc: 0.9219 - val_loss: 0.1477 - val_acc: 0.9408\n",
      "Epoch 74/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1298 - acc: 0.9478 - val_loss: 0.1924 - val_acc: 0.9159\n",
      "Epoch 75/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.1710 - acc: 0.9297 - val_loss: 0.1399 - val_acc: 0.9346\n",
      "Epoch 76/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1831 - acc: 0.9227 - val_loss: 0.1743 - val_acc: 0.9377\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1712 - acc: 0.9335 - val_loss: 0.1860 - val_acc: 0.9159\n",
      "Epoch 78/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1461 - acc: 0.9401 - val_loss: 0.2698 - val_acc: 0.9377\n",
      "Epoch 79/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1360 - acc: 0.9426 - val_loss: 0.1602 - val_acc: 0.9408\n",
      "Epoch 80/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1633 - acc: 0.9349 - val_loss: 0.1451 - val_acc: 0.9315\n",
      "Epoch 81/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1751 - acc: 0.9283 - val_loss: 0.1793 - val_acc: 0.9315\n",
      "Epoch 82/100\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.2091 - acc: 0.9002 - val_loss: 0.2016 - val_acc: 0.9315\n",
      "Epoch 83/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1332 - acc: 0.9401 - val_loss: 0.1614 - val_acc: 0.9377\n",
      "Epoch 84/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2021 - acc: 0.9126 - val_loss: 0.2418 - val_acc: 0.8972\n",
      "Epoch 85/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2280 - acc: 0.8932 - val_loss: 0.1936 - val_acc: 0.9283\n",
      "Epoch 86/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1849 - acc: 0.9204 - val_loss: 0.1877 - val_acc: 0.9283\n",
      "Epoch 87/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.1738 - acc: 0.9245 - val_loss: 0.1648 - val_acc: 0.9315\n",
      "Epoch 88/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1683 - acc: 0.9400 - val_loss: 0.2096 - val_acc: 0.9221\n",
      "Epoch 89/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1840 - acc: 0.9244 - val_loss: 0.1727 - val_acc: 0.9346\n",
      "Epoch 90/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1300 - acc: 0.9492 - val_loss: 0.2136 - val_acc: 0.9315\n",
      "Epoch 91/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1409 - acc: 0.9413 - val_loss: 0.1964 - val_acc: 0.9283\n",
      "Epoch 92/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1443 - acc: 0.9401 - val_loss: 0.1861 - val_acc: 0.9252\n",
      "Epoch 93/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1475 - acc: 0.9400 - val_loss: 0.1521 - val_acc: 0.9377\n",
      "Epoch 94/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1171 - acc: 0.9478 - val_loss: 0.1693 - val_acc: 0.9315\n",
      "Epoch 95/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.1232 - acc: 0.9544 - val_loss: 0.1547 - val_acc: 0.9470\n",
      "('Train loss:', 0.090340771286262722)\n",
      "('Train accuracy:', 0.96960249415432576)\n",
      "('Test loss:', 0.13991381307198161)\n",
      "('Test accuracy:', 0.93457943925233644)\n",
      "('\\n===================FOLD=', 2)\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 14s 587ms/step - loss: 1.9876 - acc: 0.5182 - val_loss: 0.6973 - val_acc: 0.5576\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 2s 94ms/step - loss: 1.6395 - acc: 0.5589 - val_loss: 0.5477 - val_acc: 0.7414\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 94ms/step - loss: 1.2231 - acc: 0.6667 - val_loss: 0.5302 - val_acc: 0.7321\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 1.0977 - acc: 0.7014 - val_loss: 0.3592 - val_acc: 0.8629\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 2s 103ms/step - loss: 1.0449 - acc: 0.7331 - val_loss: 0.3525 - val_acc: 0.8255\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.8313 - acc: 0.7753 - val_loss: 0.3939 - val_acc: 0.8567\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.8274 - acc: 0.7541 - val_loss: 0.8278 - val_acc: 0.6511\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.7730 - acc: 0.7565 - val_loss: 0.2459 - val_acc: 0.9034\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.5648 - acc: 0.8252 - val_loss: 0.2979 - val_acc: 0.8910\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.6879 - acc: 0.7865 - val_loss: 0.5262 - val_acc: 0.8069\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.9247 - acc: 0.7388 - val_loss: 0.2794 - val_acc: 0.8474\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.5987 - acc: 0.8226 - val_loss: 0.2267 - val_acc: 0.8972\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.6647 - acc: 0.7943 - val_loss: 0.2972 - val_acc: 0.8754\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.6146 - acc: 0.8213 - val_loss: 0.3070 - val_acc: 0.8723\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.5388 - acc: 0.8372 - val_loss: 0.3025 - val_acc: 0.8754\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.4424 - acc: 0.8500 - val_loss: 0.2456 - val_acc: 0.9128\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.5042 - acc: 0.8203 - val_loss: 0.3055 - val_acc: 0.8754\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.5025 - acc: 0.8487 - val_loss: 0.1802 - val_acc: 0.9283\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.4557 - acc: 0.8513 - val_loss: 0.3033 - val_acc: 0.8879\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.4807 - acc: 0.8177 - val_loss: 0.2240 - val_acc: 0.9190\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.4364 - acc: 0.8484 - val_loss: 0.2514 - val_acc: 0.9097\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.3883 - acc: 0.8698 - val_loss: 0.2482 - val_acc: 0.9128\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.4103 - acc: 0.8670 - val_loss: 0.1943 - val_acc: 0.9221\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.4455 - acc: 0.8458 - val_loss: 0.1950 - val_acc: 0.9377\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.4855 - acc: 0.8372 - val_loss: 0.2393 - val_acc: 0.9003\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.3750 - acc: 0.8878 - val_loss: 0.3050 - val_acc: 0.8816\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 0.4508 - acc: 0.8398 - val_loss: 0.1800 - val_acc: 0.9252\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.3698 - acc: 0.8800 - val_loss: 0.2035 - val_acc: 0.9283\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.3956 - acc: 0.8516 - val_loss: 0.1982 - val_acc: 0.9190\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.3052 - acc: 0.8918 - val_loss: 0.2647 - val_acc: 0.9097\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.3236 - acc: 0.8787 - val_loss: 0.1998 - val_acc: 0.9252\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2928 - acc: 0.8906 - val_loss: 0.1931 - val_acc: 0.9252\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.3219 - acc: 0.8957 - val_loss: 0.1741 - val_acc: 0.9252\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2720 - acc: 0.8958 - val_loss: 0.1948 - val_acc: 0.9252\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.3183 - acc: 0.8735 - val_loss: 0.1834 - val_acc: 0.9190\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.3041 - acc: 0.8826 - val_loss: 0.2098 - val_acc: 0.9190\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2637 - acc: 0.9036 - val_loss: 0.2131 - val_acc: 0.9252\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.3144 - acc: 0.8670 - val_loss: 0.2629 - val_acc: 0.8910\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2803 - acc: 0.8854 - val_loss: 0.3370 - val_acc: 0.8816\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2680 - acc: 0.8931 - val_loss: 0.2174 - val_acc: 0.9190\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 2s 100ms/step - loss: 0.2841 - acc: 0.8957 - val_loss: 0.1962 - val_acc: 0.9283\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2068 - acc: 0.9154 - val_loss: 0.2259 - val_acc: 0.9221\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2419 - acc: 0.8957 - val_loss: 0.2077 - val_acc: 0.9128\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 2s 80ms/step - loss: 0.2852 - acc: 0.8906 - val_loss: 0.2614 - val_acc: 0.8972\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2712 - acc: 0.8940 - val_loss: 0.2571 - val_acc: 0.9003\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 0.2454 - acc: 0.8906 - val_loss: 0.1555 - val_acc: 0.9315\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2623 - acc: 0.9022 - val_loss: 0.2274 - val_acc: 0.8941\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2786 - acc: 0.8944 - val_loss: 0.1836 - val_acc: 0.9252\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2321 - acc: 0.8971 - val_loss: 0.1699 - val_acc: 0.9346\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2478 - acc: 0.9058 - val_loss: 0.1771 - val_acc: 0.9346\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2201 - acc: 0.9141 - val_loss: 0.1878 - val_acc: 0.9128\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2392 - acc: 0.9022 - val_loss: 0.2381 - val_acc: 0.9097\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2399 - acc: 0.8996 - val_loss: 0.2483 - val_acc: 0.9097\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2082 - acc: 0.9115 - val_loss: 0.2149 - val_acc: 0.9190\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2075 - acc: 0.9009 - val_loss: 0.1855 - val_acc: 0.9377\n",
      "Epoch 56/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.1948 - acc: 0.9284 - val_loss: 0.2204 - val_acc: 0.9065\n",
      "Epoch 57/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2340 - acc: 0.9022 - val_loss: 0.1990 - val_acc: 0.9283\n",
      "Epoch 58/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.1996 - acc: 0.9076 - val_loss: 0.2736 - val_acc: 0.9283\n",
      "Epoch 59/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.3266 - acc: 0.8627 - val_loss: 0.2385 - val_acc: 0.8910\n",
      "Epoch 60/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2444 - acc: 0.8823 - val_loss: 0.2153 - val_acc: 0.9034\n",
      "Epoch 61/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.2098 - acc: 0.9206 - val_loss: 0.1761 - val_acc: 0.9346\n",
      "Epoch 62/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.1486 - acc: 0.9413 - val_loss: 0.1693 - val_acc: 0.9283\n",
      "Epoch 63/100\n",
      "24/24 [==============================] - 2s 81ms/step - loss: 0.1820 - acc: 0.9219 - val_loss: 0.1970 - val_acc: 0.9439\n",
      "Epoch 64/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.1442 - acc: 0.9426 - val_loss: 0.2055 - val_acc: 0.9190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1819 - acc: 0.9257 - val_loss: 0.1874 - val_acc: 0.9377\n",
      "Epoch 66/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1695 - acc: 0.9258 - val_loss: 0.2078 - val_acc: 0.9315\n",
      "('Train loss:', 0.14219989391248483)\n",
      "('Train accuracy:', 0.93764614185502726)\n",
      "('Test loss:', 0.15553328580574083)\n",
      "('Test accuracy:', 0.93146417445482865)\n",
      "('\\n===================FOLD=', 3)\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 14s 588ms/step - loss: 1.4362 - acc: 0.5221 - val_loss: 1.4434 - val_acc: 0.5312\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 1.0915 - acc: 0.5725 - val_loss: 0.7460 - val_acc: 0.6312\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.8377 - acc: 0.6341 - val_loss: 0.5226 - val_acc: 0.7531\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.9002 - acc: 0.6461 - val_loss: 0.6926 - val_acc: 0.7031\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 2s 94ms/step - loss: 0.6511 - acc: 0.7617 - val_loss: 0.4427 - val_acc: 0.7781\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.5701 - acc: 0.7748 - val_loss: 0.4643 - val_acc: 0.7438\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5069 - acc: 0.7947 - val_loss: 0.3628 - val_acc: 0.8375\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.4781 - acc: 0.8138 - val_loss: 0.4036 - val_acc: 0.8250\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 0.4983 - acc: 0.7986 - val_loss: 0.3409 - val_acc: 0.8250\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.4414 - acc: 0.8385 - val_loss: 0.4632 - val_acc: 0.7969\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.4329 - acc: 0.8117 - val_loss: 0.3949 - val_acc: 0.8219\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3649 - acc: 0.8579 - val_loss: 0.4113 - val_acc: 0.8406\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3335 - acc: 0.8685 - val_loss: 0.3801 - val_acc: 0.8000\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.3380 - acc: 0.8504 - val_loss: 0.4562 - val_acc: 0.8156\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2895 - acc: 0.8763 - val_loss: 0.3417 - val_acc: 0.8594\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3557 - acc: 0.8726 - val_loss: 0.3662 - val_acc: 0.8438\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2632 - acc: 0.9023 - val_loss: 0.4145 - val_acc: 0.8438\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2321 - acc: 0.9139 - val_loss: 0.4602 - val_acc: 0.8375\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.3293 - acc: 0.8722 - val_loss: 0.3690 - val_acc: 0.8406\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2818 - acc: 0.8828 - val_loss: 0.3511 - val_acc: 0.8438\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.3187 - acc: 0.8608 - val_loss: 0.3386 - val_acc: 0.8562\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3398 - acc: 0.8711 - val_loss: 0.3752 - val_acc: 0.8281\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2948 - acc: 0.8778 - val_loss: 0.3631 - val_acc: 0.8531\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2951 - acc: 0.8931 - val_loss: 0.4039 - val_acc: 0.8406\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2766 - acc: 0.8945 - val_loss: 0.4034 - val_acc: 0.8531\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3010 - acc: 0.8700 - val_loss: 0.4148 - val_acc: 0.8406\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2679 - acc: 0.8815 - val_loss: 0.3739 - val_acc: 0.8406\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2469 - acc: 0.8957 - val_loss: 0.4550 - val_acc: 0.8469\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2886 - acc: 0.8958 - val_loss: 0.3518 - val_acc: 0.8656\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2402 - acc: 0.9009 - val_loss: 0.4998 - val_acc: 0.8031\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1945 - acc: 0.9165 - val_loss: 0.3487 - val_acc: 0.8688\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2447 - acc: 0.8932 - val_loss: 0.4101 - val_acc: 0.8375\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2400 - acc: 0.9074 - val_loss: 0.3715 - val_acc: 0.8625\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2249 - acc: 0.9180 - val_loss: 0.4386 - val_acc: 0.8531\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.2395 - acc: 0.8947 - val_loss: 0.3038 - val_acc: 0.8719\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.1934 - acc: 0.9178 - val_loss: 0.3704 - val_acc: 0.8562\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 2s 79ms/step - loss: 0.2538 - acc: 0.8919 - val_loss: 0.3590 - val_acc: 0.8313\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1864 - acc: 0.9130 - val_loss: 0.3230 - val_acc: 0.8719\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2031 - acc: 0.9206 - val_loss: 0.3748 - val_acc: 0.8688\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.1728 - acc: 0.9296 - val_loss: 0.3756 - val_acc: 0.8500\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 0.1823 - acc: 0.9244 - val_loss: 0.3571 - val_acc: 0.8656\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.1825 - acc: 0.9310 - val_loss: 0.3242 - val_acc: 0.8531\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2247 - acc: 0.9000 - val_loss: 0.3260 - val_acc: 0.8438\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1773 - acc: 0.9323 - val_loss: 0.4167 - val_acc: 0.8594\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2060 - acc: 0.9039 - val_loss: 0.3666 - val_acc: 0.8594\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.1377 - acc: 0.9323 - val_loss: 0.4213 - val_acc: 0.8500\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1760 - acc: 0.9270 - val_loss: 0.3606 - val_acc: 0.8594\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1629 - acc: 0.9309 - val_loss: 0.3504 - val_acc: 0.8719\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1532 - acc: 0.9388 - val_loss: 0.3704 - val_acc: 0.8688\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1507 - acc: 0.9309 - val_loss: 0.3534 - val_acc: 0.8438\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1450 - acc: 0.9427 - val_loss: 0.3370 - val_acc: 0.8656\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1686 - acc: 0.9309 - val_loss: 0.4002 - val_acc: 0.8688\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.1532 - acc: 0.9387 - val_loss: 0.4067 - val_acc: 0.8531\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.1706 - acc: 0.9245 - val_loss: 0.3766 - val_acc: 0.8375\n",
      "Epoch 55/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2290 - acc: 0.9078 - val_loss: 0.3453 - val_acc: 0.8438\n",
      "('Train loss:', 0.12752600817294135)\n",
      "('Train accuracy:', 0.95638629283489096)\n",
      "('Test loss:', 0.30377405583858491)\n",
      "('Test accuracy:', 0.87187499999999996)\n",
      "('\\n===================FOLD=', 4)\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 14s 588ms/step - loss: 1.6356 - acc: 0.5885 - val_loss: 0.5073 - val_acc: 0.7375\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 1.0996 - acc: 0.6926 - val_loss: 0.4379 - val_acc: 0.8094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 1.0519 - acc: 0.6797 - val_loss: 0.5471 - val_acc: 0.7906\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 2s 90ms/step - loss: 1.0610 - acc: 0.7165 - val_loss: 0.3956 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 0.7756 - acc: 0.7617 - val_loss: 0.3882 - val_acc: 0.8531\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 2s 92ms/step - loss: 0.8576 - acc: 0.7578 - val_loss: 0.3715 - val_acc: 0.8406\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.6852 - acc: 0.8161 - val_loss: 0.3518 - val_acc: 0.8438\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 2s 93ms/step - loss: 0.6053 - acc: 0.8008 - val_loss: 0.2945 - val_acc: 0.8625\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.5407 - acc: 0.8292 - val_loss: 0.4127 - val_acc: 0.8562\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.5604 - acc: 0.8346 - val_loss: 0.3791 - val_acc: 0.8438\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.5604 - acc: 0.7999 - val_loss: 0.3156 - val_acc: 0.8531\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 2s 74ms/step - loss: 0.5649 - acc: 0.7973 - val_loss: 0.3609 - val_acc: 0.8531\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.5104 - acc: 0.8372 - val_loss: 0.3548 - val_acc: 0.8656\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.5172 - acc: 0.8226 - val_loss: 0.3532 - val_acc: 0.8406\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 0.4644 - acc: 0.8438 - val_loss: 0.2785 - val_acc: 0.8688\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.4053 - acc: 0.8526 - val_loss: 0.2824 - val_acc: 0.8781\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.4555 - acc: 0.8307 - val_loss: 0.2864 - val_acc: 0.8656\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3486 - acc: 0.8644 - val_loss: 0.3629 - val_acc: 0.8562\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.4238 - acc: 0.8370 - val_loss: 0.3129 - val_acc: 0.8750\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.3391 - acc: 0.8685 - val_loss: 0.2814 - val_acc: 0.8688\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3349 - acc: 0.8687 - val_loss: 0.3454 - val_acc: 0.8531\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.4065 - acc: 0.8581 - val_loss: 0.3076 - val_acc: 0.8531\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3755 - acc: 0.8631 - val_loss: 0.3053 - val_acc: 0.8750\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.4188 - acc: 0.8391 - val_loss: 0.3236 - val_acc: 0.8656\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.3506 - acc: 0.8607 - val_loss: 0.3679 - val_acc: 0.8875\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3815 - acc: 0.8312 - val_loss: 0.2819 - val_acc: 0.8844\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.3253 - acc: 0.8802 - val_loss: 0.2565 - val_acc: 0.8844\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.3155 - acc: 0.8735 - val_loss: 0.3924 - val_acc: 0.8406\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 2s 95ms/step - loss: 0.2598 - acc: 0.9023 - val_loss: 0.2552 - val_acc: 0.8969\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.3109 - acc: 0.8804 - val_loss: 0.2493 - val_acc: 0.8844\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2161 - acc: 0.9218 - val_loss: 0.3414 - val_acc: 0.8719\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2510 - acc: 0.8958 - val_loss: 0.2643 - val_acc: 0.8688\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 2s 89ms/step - loss: 0.2623 - acc: 0.8830 - val_loss: 0.2344 - val_acc: 0.8844\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 2s 94ms/step - loss: 0.2220 - acc: 0.9036 - val_loss: 0.2274 - val_acc: 0.8969\n",
      "Epoch 35/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2565 - acc: 0.8860 - val_loss: 0.2918 - val_acc: 0.8594\n",
      "Epoch 36/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2440 - acc: 0.9104 - val_loss: 0.2725 - val_acc: 0.8719\n",
      "Epoch 37/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2341 - acc: 0.9010 - val_loss: 0.2743 - val_acc: 0.8875\n",
      "Epoch 38/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2331 - acc: 0.9035 - val_loss: 0.2638 - val_acc: 0.8781\n",
      "Epoch 39/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.2187 - acc: 0.9036 - val_loss: 0.2974 - val_acc: 0.8938\n",
      "Epoch 40/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2578 - acc: 0.8947 - val_loss: 0.2756 - val_acc: 0.8844\n",
      "Epoch 41/100\n",
      "24/24 [==============================] - 2s 91ms/step - loss: 0.2086 - acc: 0.9257 - val_loss: 0.3668 - val_acc: 0.8438\n",
      "Epoch 42/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2018 - acc: 0.9128 - val_loss: 0.2721 - val_acc: 0.8969\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2116 - acc: 0.9126 - val_loss: 0.2873 - val_acc: 0.8875\n",
      "Epoch 44/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1793 - acc: 0.9284 - val_loss: 0.2664 - val_acc: 0.8688\n",
      "Epoch 45/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1919 - acc: 0.9113 - val_loss: 0.2801 - val_acc: 0.8938\n",
      "Epoch 46/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.1797 - acc: 0.9180 - val_loss: 0.3030 - val_acc: 0.8844\n",
      "Epoch 47/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2315 - acc: 0.8905 - val_loss: 0.2422 - val_acc: 0.8938\n",
      "Epoch 48/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2513 - acc: 0.8921 - val_loss: 0.3869 - val_acc: 0.8375\n",
      "Epoch 49/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.3407 - acc: 0.8424 - val_loss: 0.3046 - val_acc: 0.8656\n",
      "Epoch 50/100\n",
      "24/24 [==============================] - 2s 75ms/step - loss: 0.2394 - acc: 0.8996 - val_loss: 0.2476 - val_acc: 0.9000\n",
      "Epoch 51/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.2549 - acc: 0.8854 - val_loss: 0.2569 - val_acc: 0.8844\n",
      "Epoch 52/100\n",
      "24/24 [==============================] - 2s 77ms/step - loss: 0.1848 - acc: 0.9104 - val_loss: 0.3819 - val_acc: 0.8719\n",
      "Epoch 53/100\n",
      "24/24 [==============================] - 2s 76ms/step - loss: 0.2248 - acc: 0.9013 - val_loss: 0.2496 - val_acc: 0.8969\n",
      "Epoch 54/100\n",
      "24/24 [==============================] - 2s 78ms/step - loss: 0.1863 - acc: 0.9245 - val_loss: 0.3007 - val_acc: 0.8812\n",
      "('Train loss:', 0.1597707573544942)\n",
      "('Train accuracy:', 0.94392523364485981)\n",
      "('Test loss:', 0.22740184366703034)\n",
      "('Test accuracy:', 0.89687499999999998)\n",
      "('\\n Train Log Loss Validation= ', 0.1884113273332485)\n",
      "(' Test Log Loss Validation= ', 0.2676366122361703)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from os.path import join as opj\n",
    "import keras\n",
    "import cv2\n",
    "#from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#import pylab\n",
    "#plt.rcParams['figure.figsize'] = 10, 10\n",
    "#%matplotlib inline\n",
    "\n",
    "train = pd.read_json(\"kaggle_lceberg_data/train.json\")\n",
    "target_train=train['is_iceberg']\n",
    "test = pd.read_json(\"kaggle_lceberg_data/test.json\")\n",
    "\n",
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle=test['inc_angle']\n",
    "\n",
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "#X_band_3=(X_band_1+X_band_2)/2\n",
    "X_band_3=np.fabs(np.subtract(X_band_1,X_band_2))\n",
    "X_band_4=np.maximum(X_band_1,X_band_2)\n",
    "X_band_5=np.minimum(X_band_1,X_band_2)\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([\n",
    "                          \n",
    "                          X_band_3[:, :, :, np.newaxis],X_band_4[:, :, :, np.newaxis],X_band_5[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "#X_band_test_3=(X_band_test_1+X_band_test_2)/2\n",
    "X_band_test_3=np.fabs(np.subtract(X_band_test_1,X_band_test_2))\n",
    "X_band_test_4=np.maximum(X_band_test_1,X_band_test_2)\n",
    "X_band_test_5=np.minimum(X_band_test_1,X_band_test_2)\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([\n",
    "                          X_band_test_3[:, :, :, np.newaxis], X_band_test_4[:, :, :, np.newaxis],X_band_test_5[:, :, :, np.newaxis]],axis=-1)\n",
    "RESIZE = None\n",
    "# #ResNet\n",
    "# RESIZE = 197\n",
    "# #InceptionV3\n",
    "# RESIZE = 139\n",
    "#Xception\n",
    "# RESIZE = 71\n",
    "if RESIZE != None:\n",
    "    X_train_resize = np.zeros((X_train.shape[0], RESIZE, RESIZE, 3), np.float32)\n",
    "    X_test_resize = np.zeros((X_test.shape[0], RESIZE, RESIZE, 3), np.float32)\n",
    "    # X_train_resize[:,...] = cv2.resize(X_train[:,...], (197, 197))\n",
    "    # print \"train data set resize done!\"\n",
    "    # X_test_resize[:,...] = cv2.resize(X_test[:,...], (197, 197))\n",
    "    # print \"test data set resize done!\"\n",
    "    for i in range(X_train.shape[0]):\n",
    "    #     a = X_train[i]\n",
    "        X_train_resize[i] = cv2.resize(X_train[i], (RESIZE, RESIZE))\n",
    "    #     X_train[i] = a\n",
    "    print \"train data set resize done!\"\n",
    "    for i in range(X_test.shape[0]):\n",
    "    #     a = X_test[i]\n",
    "        X_test_resize[i] = cv2.resize(X_test[i], (RESIZE, RESIZE))\n",
    "    #     X_test[i] = a\n",
    "    print \"test data set resize done!\"\n",
    "#Import Keras.\n",
    "#from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Data Aug for multi-input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=32\n",
    "PARA_PATH = './VGG16/'\n",
    "# Define the image transformations here\n",
    "# gen = ImageDataGenerator(horizontal_flip = True,\n",
    "#                          vertical_flip = True,\n",
    "#                          width_shift_range = 0.,\n",
    "#                          height_shift_range = 0.,\n",
    "#                          channel_shift_range=0,\n",
    "#                          zoom_range = 0.5,\n",
    "#                          rotation_range = 10)\n",
    "gen = ImageDataGenerator(width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 20,\n",
    "                         horizontal_flip = True)\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size,seed=55)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size,seed=55)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "def get_callbacks(filepath, patience=2):\n",
    "   #es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "   es = EarlyStopping('val_loss', patience=20, mode=\"min\")\n",
    "   msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "   return [es, msave]\n",
    "\n",
    "\n",
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "#     base_model2 = keras.applications.mobilenet.MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train.shape[1:])\n",
    "\n",
    "#     x2 = base_model2.output\n",
    "#     x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "#     merge_one = concatenate([x, x2, angle_layer])\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dropout(0.5)(merge_one)\n",
    "    \n",
    "#     dense_layer = Dropout( 0.5 ) ( BatchNormalization(momentum=0.99) (Dense(4096, activation = 'relu') (merge_one)) )\n",
    "#     merge_one = Dropout( 0.5 ) ( BatchNormalization(momentum=bn_momentum) (Dense(4096, activation = 'relu') (dense_layer)) )\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = Adam(lr=1e-4) #SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def getResNet50AngleModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train_resize.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('avg_pool').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     base_model2 = keras.applications.mobilenet.MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train.shape[1:])\n",
    "\n",
    "#     x2 = base_model2.output\n",
    "#     x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "#     merge_one = concatenate([x, x2, angle_layer])\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dropout(0.5)(merge_one)\n",
    "    \n",
    "#     dense_layer = Dropout( 0.5 ) ( BatchNormalization(momentum=0.99) (Dense(4096, activation = 'relu') (merge_one)) )\n",
    "#     merge_one = Dropout( 0.5 ) ( BatchNormalization(momentum=bn_momentum) (Dense(4096, activation = 'relu') (dense_layer)) )\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = Adam(lr=1e-4) #SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def InceptionV3Model():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train_resize.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('mixed10').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "#     base_model2 = keras.applications.mobilenet.MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train.shape[1:])\n",
    "\n",
    "#     x2 = base_model2.output\n",
    "#     x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "#     merge_one = concatenate([x, x2, angle_layer])\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dropout(0.5)(merge_one)\n",
    "    \n",
    "#     dense_layer = Dropout( 0.5 ) ( BatchNormalization(momentum=0.99) (Dense(4096, activation = 'relu') (merge_one)) )\n",
    "#     merge_one = Dropout( 0.5 ) ( BatchNormalization(momentum=bn_momentum) (Dense(4096, activation = 'relu') (dense_layer)) )\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = Adam(lr=1e-4) #SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def XceptionModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = Xception(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block14_sepconv2_act').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "#     base_model2 = keras.applications.mobilenet.MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train.shape[1:])\n",
    "\n",
    "#     x2 = base_model2.output\n",
    "#     x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "#     merge_one = concatenate([x, x2, angle_layer])\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dropout(0.5)(merge_one)\n",
    "    \n",
    "#     dense_layer = Dropout( 0.5 ) ( BatchNormalization(momentum=0.99) (Dense(4096, activation = 'relu') (merge_one)) )\n",
    "#     merge_one = Dropout( 0.5 ) ( BatchNormalization(momentum=bn_momentum) (Dense(4096, activation = 'relu') (dense_layer)) )\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = Adam(lr=1e-4) #SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def MobileNetModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train_resize.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('conv_pw_13_bn').output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "#     base_model2 = keras.applications.mobilenet.MobileNet(weights=None, alpha=0.9,input_tensor = base_model.input,include_top=False, input_shape=X_train.shape[1:])\n",
    "\n",
    "#     x2 = base_model2.output\n",
    "#     x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "#     merge_one = concatenate([x, x2, angle_layer])\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dropout(0.5)(merge_one)\n",
    "    \n",
    "#     dense_layer = Dropout( 0.5 ) ( BatchNormalization(momentum=0.99) (Dense(4096, activation = 'relu') (merge_one)) )\n",
    "#     merge_one = Dropout( 0.5 ) ( BatchNormalization(momentum=bn_momentum) (Dense(4096, activation = 'relu') (dense_layer)) )\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid',kernel_initializer='he_normal')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = Adam(lr=1e-4) #SGD(lr=1e-4, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    K=5\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=16).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log = 0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = PARA_PATH + \"%s_aug_model_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=10)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        galaxyModel= getVggAngleModel()\n",
    "#         galaxyModel= getResNet50AngleModel()\n",
    "#         galaxyModel= InceptionV3Model()\n",
    "#         galaxyModel= XceptionModel()\n",
    "#         galaxyModel= MobileNetModel()\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=24,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log\n",
    "\n",
    "# preds=myAngleCV(X_train_resize, X_angle, X_test_resize)\n",
    "preds=myAngleCV(X_train, X_angle, X_test)\n",
    "#Submission for each day.\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv(PARA_PATH + 'sub201801141429VGG16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
